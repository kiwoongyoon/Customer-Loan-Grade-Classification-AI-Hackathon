{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Jan 31 09:45:40 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.8.3296). Expected < 9.8.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Jan 31 09:45:40 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.8.3296). Expected < 9.8.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import  f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from optbinning import OptimalBinning\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from sklearn.decomposition import PCA\n",
    "from functools import reduce\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import optuna\n",
    "from optuna import Trial\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.samplers import TPESampler\n",
    "sampler = TPESampler(seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "sample_submission = pd.read_csv('../data/sample_submission.csv')\n",
    "original_columns = test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_years(s):\n",
    "    if \"unknown\" in s.lower():\n",
    "        return np.nan  # or return some specific value\n",
    "    elif \"<\" in s:\n",
    "        return 0.5\n",
    "    elif \"+\" in s :\n",
    "        return 12 \n",
    "    else:\n",
    "        return int(re.search(r'\\d+', s).group())\n",
    "    \n",
    "train['근로기간']= train['근로기간'].apply(extract_years)\n",
    "test['근로기간']= test['근로기간'].apply(extract_years)\n",
    "\n",
    "train['대출기간'] = train['대출기간'].apply(lambda x : int(x.split()[0]))\n",
    "test['대출기간'] = test['대출기간'].apply(lambda x : int(x.split()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade_dict = {'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6}\n",
    "column_dict = {\n",
    "    '대출금액': 'amount',\n",
    "    '대출기간': 'term',\n",
    "    '근로기간': 'workperiod',\n",
    "    '주택소유상태': 'homeown',\n",
    "    '연간소득': 'income',\n",
    "    '부채_대비_소득_비율': 'detinratio',\n",
    "    '총계좌수': 'account_cnt',\n",
    "    '대출목적': 'purpose',\n",
    "    '최근_2년간_연체_횟수': 'delay_cnt',\n",
    "    '총상환원금': 'principal_paid',\n",
    "    '총상환이자': 'interest_paid',\n",
    "    '총연체금액': 'delinquent_amount',\n",
    "    '연체계좌수': 'delinquent_accounts',\n",
    "    '대출등급': 'grade'\n",
    "}\n",
    "\n",
    "train['대출등급'] = train['대출등급'].map(grade_dict)\n",
    "\n",
    "train = train.rename(columns=column_dict)\n",
    "test = test.rename(columns=column_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "def target_encode_multiclass_train(X,y): #X,y are pandas df and series\n",
    "    y=y.astype(str)   #convert to string to onehot encode\n",
    "    enc=ce.OneHotEncoder().fit(y)\n",
    "    y_onehot=enc.transform(y)\n",
    "    class_names=y_onehot.columns  #names of onehot encoded columns\n",
    "    X_obj=X.select_dtypes('object') #separate categorical columns\n",
    "    X=X.select_dtypes(exclude='object') \n",
    "\n",
    "    encoders = {}  # store encoders for each class\n",
    "    for class_ in class_names:\n",
    "        enc=ce.TargetEncoder()\n",
    "        enc.fit(X_obj,y_onehot[class_]) #convert all categorical columns for class_\n",
    "        encoders[class_] = enc\n",
    "        temp=enc.transform(X_obj)       #columns for class_\n",
    "        temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "        X=pd.concat([X,temp],axis=1)    #add to original dataset\n",
    "    return X, encoders\n",
    "\n",
    "def target_encode_multiclass_test(X, encoders): #X is pandas df, encoders is dict of encoders\n",
    "    X_obj=X.select_dtypes('object') #separate categorical columns\n",
    "    X=X.select_dtypes(exclude='object') \n",
    "\n",
    "    for class_, enc in encoders.items():\n",
    "        temp=enc.transform(X_obj)       #columns for class_\n",
    "        temp.columns=[str(x)+'_'+str(class_) for x in temp.columns]\n",
    "        X=pd.concat([X,temp],axis=1)    #add to original dataset\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_train = train['workperiod'].median()\n",
    "train['homeown'] = train['homeown'].replace('ANY', 'MORTGAGE')\n",
    "train['workperiod'] = train['workperiod'].fillna(median_train)\n",
    "test['workperiod'] = test['workperiod'].fillna(median_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train' 데이터프레임의 칼럼 이름을 문자열로 변환\n",
    "train.columns = train.columns.map(str)\n",
    "test.columns = test.columns.map(str)\n",
    "\n",
    "x = train.drop(['ID','grade'], axis=1 )\n",
    "y = train['grade']\n",
    "test  = test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,t_encoder =target_encode_multiclass_train(x,y)\n",
    "test = target_encode_multiclass_test(test,t_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>term</th>\n",
       "      <th>workperiod</th>\n",
       "      <th>income</th>\n",
       "      <th>detinratio</th>\n",
       "      <th>account_cnt</th>\n",
       "      <th>delay_cnt</th>\n",
       "      <th>principal_paid</th>\n",
       "      <th>interest_paid</th>\n",
       "      <th>delinquent_amount</th>\n",
       "      <th>...</th>\n",
       "      <th>homeown_grade_3</th>\n",
       "      <th>purpose_grade_3</th>\n",
       "      <th>homeown_grade_4</th>\n",
       "      <th>purpose_grade_4</th>\n",
       "      <th>homeown_grade_5</th>\n",
       "      <th>purpose_grade_5</th>\n",
       "      <th>homeown_grade_6</th>\n",
       "      <th>purpose_grade_6</th>\n",
       "      <th>homeown_grade_7</th>\n",
       "      <th>purpose_grade_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16800000</td>\n",
       "      <td>36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>132000000</td>\n",
       "      <td>19.64</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>394692</td>\n",
       "      <td>146604.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201106</td>\n",
       "      <td>0.198864</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.023539</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.068994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400000</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>89971200</td>\n",
       "      <td>15.84</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>0.145712</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.090281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17280000</td>\n",
       "      <td>36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>150000000</td>\n",
       "      <td>8.41</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1786980</td>\n",
       "      <td>281820.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.035796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14400000</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>66000000</td>\n",
       "      <td>13.72</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>669024</td>\n",
       "      <td>281724.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201106</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.035796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27600000</td>\n",
       "      <td>36</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55200000</td>\n",
       "      <td>30.50</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1250052</td>\n",
       "      <td>614844.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>0.262204</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.035796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64192</th>\n",
       "      <td>30000000</td>\n",
       "      <td>36</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78000000</td>\n",
       "      <td>22.08</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>1307532</td>\n",
       "      <td>763380.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201106</td>\n",
       "      <td>0.145712</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.090281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64193</th>\n",
       "      <td>30000000</td>\n",
       "      <td>60</td>\n",
       "      <td>12.0</td>\n",
       "      <td>109200000</td>\n",
       "      <td>12.06</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>960612</td>\n",
       "      <td>1245252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201106</td>\n",
       "      <td>0.145712</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.090281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64194</th>\n",
       "      <td>6120000</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39600000</td>\n",
       "      <td>28.80</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>131520</td>\n",
       "      <td>80880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>0.145712</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.090281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64195</th>\n",
       "      <td>11520000</td>\n",
       "      <td>36</td>\n",
       "      <td>12.0</td>\n",
       "      <td>66000000</td>\n",
       "      <td>25.44</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1339536</td>\n",
       "      <td>601872.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201106</td>\n",
       "      <td>0.145712</td>\n",
       "      <td>0.128570</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.018421</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.072014</td>\n",
       "      <td>0.090281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64196</th>\n",
       "      <td>6000000</td>\n",
       "      <td>36</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180000000</td>\n",
       "      <td>9.07</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>308880</td>\n",
       "      <td>48960.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139716</td>\n",
       "      <td>0.145712</td>\n",
       "      <td>0.149927</td>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.023772</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.090281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64197 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount  term  workperiod     income  detinratio  account_cnt  \\\n",
       "0      16800000    36         8.0  132000000       19.64           12   \n",
       "1       8400000    36         5.0   89971200       15.84           25   \n",
       "2      17280000    36         6.0  150000000        8.41           20   \n",
       "3      14400000    36         5.0   66000000       13.72           30   \n",
       "4      27600000    36         5.0   55200000       30.50           12   \n",
       "...         ...   ...         ...        ...         ...          ...   \n",
       "64192  30000000    36         3.0   78000000       22.08           27   \n",
       "64193  30000000    60        12.0  109200000       12.06           26   \n",
       "64194   6120000    36        12.0   39600000       28.80           33   \n",
       "64195  11520000    36        12.0   66000000       25.44           41   \n",
       "64196   6000000    36         9.0  180000000        9.07           10   \n",
       "\n",
       "       delay_cnt  principal_paid  interest_paid  delinquent_amount  ...  \\\n",
       "0              0          394692       146604.0                0.0  ...   \n",
       "1              0               0            0.0                0.0  ...   \n",
       "2              0         1786980       281820.0                0.0  ...   \n",
       "3              1          669024       281724.0                0.0  ...   \n",
       "4              0         1250052       614844.0                0.0  ...   \n",
       "...          ...             ...            ...                ...  ...   \n",
       "64192          2         1307532       763380.0                0.0  ...   \n",
       "64193          0          960612      1245252.0                0.0  ...   \n",
       "64194          0          131520        80880.0                0.0  ...   \n",
       "64195          1         1339536       601872.0                0.0  ...   \n",
       "64196          0          308880        48960.0                0.0  ...   \n",
       "\n",
       "       homeown_grade_3  purpose_grade_3  homeown_grade_4  purpose_grade_4  \\\n",
       "0             0.201106         0.198864         0.128570         0.130682   \n",
       "1             0.139716         0.145712         0.149927         0.154651   \n",
       "2             0.139716         0.262204         0.149927         0.085388   \n",
       "3             0.201106         0.262204         0.128570         0.085388   \n",
       "4             0.139716         0.262204         0.149927         0.085388   \n",
       "...                ...              ...              ...              ...   \n",
       "64192         0.201106         0.145712         0.128570         0.154651   \n",
       "64193         0.201106         0.145712         0.128570         0.154651   \n",
       "64194         0.139716         0.145712         0.149927         0.154651   \n",
       "64195         0.201106         0.145712         0.128570         0.154651   \n",
       "64196         0.139716         0.145712         0.149927         0.154651   \n",
       "\n",
       "       homeown_grade_5  purpose_grade_5  homeown_grade_6  purpose_grade_6  \\\n",
       "0             0.018421         0.023539         0.003588         0.004221   \n",
       "1             0.022676         0.023772         0.005172         0.004823   \n",
       "2             0.022676         0.005592         0.005172         0.000694   \n",
       "3             0.018421         0.005592         0.003588         0.000694   \n",
       "4             0.022676         0.005592         0.005172         0.000694   \n",
       "...                ...              ...              ...              ...   \n",
       "64192         0.018421         0.023772         0.003588         0.004823   \n",
       "64193         0.018421         0.023772         0.003588         0.004823   \n",
       "64194         0.022676         0.023772         0.005172         0.004823   \n",
       "64195         0.018421         0.023772         0.003588         0.004823   \n",
       "64196         0.022676         0.023772         0.005172         0.004823   \n",
       "\n",
       "       homeown_grade_7  purpose_grade_7  \n",
       "0             0.072014         0.068994  \n",
       "1             0.081050         0.090281  \n",
       "2             0.081050         0.035796  \n",
       "3             0.072014         0.035796  \n",
       "4             0.081050         0.035796  \n",
       "...                ...              ...  \n",
       "64192         0.072014         0.090281  \n",
       "64193         0.072014         0.090281  \n",
       "64194         0.081050         0.090281  \n",
       "64195         0.072014         0.090281  \n",
       "64196         0.081050         0.090281  \n",
       "\n",
       "[64197 rows x 25 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier,BaggingClassifier\n",
    "lgbm= LGBMClassifier( random_state=42)\n",
    "xgb =XGBClassifier(random_state =42)\n",
    "bag = BaggingClassifier(random_state=42)\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lgbm', lgbm), ('xgb', xgb), ('bag', bag) ],\n",
    "    voting='soft',  weights=[0.2,0.6,0.3]\n",
    ")\n",
    "# 모델 학습\n",
    "voting_clf.fit(x, y)\n",
    "\n",
    "# 예측\n",
    "pred = voting_clf.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13169/1543345230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[var+'_log'] = np.log(train[var]+1)\n",
      "/tmp/ipykernel_13169/1543345230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[var+'_log'] = np.log(train[var]+1)\n",
      "/tmp/ipykernel_13169/1543345230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[var+'_log'] = np.log(train[var]+1)\n",
      "/tmp/ipykernel_13169/1543345230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[var+'_log'] = np.log(train[var]+1)\n",
      "/tmp/ipykernel_13169/1543345230.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train[var+'_log'] = np.log(train[var]+1)\n"
     ]
    }
   ],
   "source": [
    "for var in ['income','account_cnt','principal_paid','interest_paid','delinquent_amount']:\n",
    "    train[var+'_log'] = np.log(train[var]+1)\n",
    "    test[var+'_log'] = np.log(test[var]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# # 스케일링할 열 선택\n",
    "# columns_to_scale = ['income', 'principal_paid', 'interest_paid','account_cnt']\n",
    "# # MinMaxScaler 객체 생성\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# # 훈련 데이터에 대해 fit과 transform 수행\n",
    "# train[columns_to_scale] = scaler.fit_transform(train[columns_to_scale])\n",
    "# test[columns_to_scale] = scaler.transform(test[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Operation\n",
    "for group in ['term', 'homeown', 'purpose' ]:\n",
    "    for num_var in ['amount', 'income','detinratio','delay_cnt','principal_paid','interest_paid','delinquent_amount']:\n",
    "      \n",
    "        train,test= train.copy(), test.copy()\n",
    "        \n",
    "        for stat in ['mean', 'median']:\n",
    "            stat_dict = train.groupby([group])[num_var].agg(stat).to_dict()\n",
    "            \n",
    "            train[num_var +'_'+group + '_'+ stat]= train[group].map(stat_dict)\n",
    "            test[num_var +'_'+group + '_'+ stat]= test[group].map(stat_dict)\n",
    "            \n",
    "            train[num_var+'_minus_'+num_var+'_'+group+'_'+stat] = train[num_var] - train[num_var+'_'+group+'_'+stat]\n",
    "            test[num_var+'_minus_'+num_var+'_'+group+'_'+stat] = test[num_var] - test[num_var+'_'+group+'_'+stat]\n",
    "            \n",
    "            train[num_var+'_divide_'+num_var+'_'+group+'_'+stat] = np.log(train[num_var]+0.00001) / np.log(train[num_var+'_'+group+'_'+stat]+0.00001)\n",
    "            test[num_var+'_divide_'+num_var+'_'+group+'_'+stat] = np.log(test[num_var]+0.00001) / np.log(test[num_var+'_'+group+'_'+stat]+0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Woe Features\n",
    "from optbinning import OptimalBinning\n",
    "for variable in ['amount','income','detinratio','principal_paid','interest_paid','term']:\n",
    "\n",
    "    optb = OptimalBinning(name=variable, dtype=\"numerical\", solver=\"cp\")\n",
    "\n",
    "    x = train[variable].values\n",
    "    y = train['grade']\n",
    "\n",
    "    optb.fit(x, y)\n",
    "\n",
    "    binning_table = optb.binning_table\n",
    "\n",
    "    a1 = binning_table.build()\n",
    "    \n",
    "    train[variable+'_woe'] = pd.cut(train[variable],bins=optb.splits.tolist()).astype(str)\n",
    "    test[variable+'_woe'] = pd.cut(test[variable],bins=optb.splits.tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 클러스터링할 피처들을 지정합니다.\n",
    "features = ['amount','income','detinratio','interest_paid']\n",
    "\n",
    "# 최적의 클러스터 수로 KMeans 모델을 생성하고 학습합니다.\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', max_iter=800, n_init=25, random_state=42)\n",
    "kmeans.fit(train[features])\n",
    "\n",
    "# 학습 데이터에 클러스터 번호를 추가합니다.\n",
    "train['clust_num'] = kmeans.predict(train[features])\n",
    "\n",
    "# 동일한 모델을 사용해 테스트 데이터에도 클러스터 번호를 추가합니다.\n",
    "test['clust_num'] = kmeans.predict(test[features])\n",
    "\n",
    "\n",
    "for var in ['income','principal_paid','interest_paid']:\n",
    "    a1 = train.groupby(['clust_num'])[var].mean().to_dict() \n",
    "    train['clnum_'+var] = train['clust_num'].map(a1)\n",
    "    test['clnum_'+var] = test['clust_num'].map(a1)\n",
    "    \n",
    "    a1 = train.groupby(['clust_num'])[var].min().to_dict()\n",
    "    train['clnum2_'+var]= train['clust_num'].map(a1)\n",
    "    test['clnum2_'+var]= test['clust_num'].map(a1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코딩 처리하기 \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "test['purpose'] = test['purpose'].replace('결혼', '기타')\n",
    "# # 원-핫 인코더 생성\n",
    "# encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "encoder = LabelEncoder() \n",
    "# 'amount','income','detinratio','principal_paid','interest_paid','term'\n",
    "for column in ['homeown','purpose','amount_woe','term_woe','income_woe','detinratio_woe','principal_paid_woe','interest_paid_woe']:\n",
    "    # train 데이터를 기반으로 인코딩을 학습하고 적용\n",
    "    encoder.fit(train[column])\n",
    "    train[column] = encoder.transform(train[column])\n",
    "    test[column] = encoder.transform(test[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature making\n",
    "from itertools import chain, product \n",
    "# candidate_var = ['detinratio','amount','term','income','account_cnt','principal_paid','interest_paid'],['amount','workperiod','income','detinratio','account_cnt','principal_paid','interest_paid']\n",
    "candidate_var =['amount','workperiod','income','detinratio','account_cnt','principal_paid','interest_paid']\n",
    "pairs = list(chain(product(candidate_var, candidate_var), product(candidate_var, candidate_var))) \n",
    "pairs = pd.Series([sorted([i,j]) for (i,j) in set(pairs) if i!=j]).drop_duplicates().reset_index(drop=True).tolist()\n",
    "pairs = sorted(pairs)\n",
    "\n",
    "epsilon = 0.001  # 분모에 더해줄 작은 값\n",
    "\n",
    "for i in range(len(pairs)):\n",
    "    train[pairs[i][0]+'M'+pairs[i][1]] = train[pairs[i][0]] * train[pairs[i][1]]\n",
    "    test[pairs[i][0]+'M'+pairs[i][1]] = test[pairs[i][0]] * test[pairs[i][1]]\n",
    "    \n",
    "    # 분모에 작은 값을 더해서 나눗셈 수행\n",
    "    train[pairs[i][0]+'D'+pairs[i][1]] = train[pairs[i][0]] / (train[pairs[i][1]] + epsilon)\n",
    "    test[pairs[i][0]+'D'+pairs[i][1]] = test[pairs[i][0]] / (test[pairs[i][1]] + epsilon)\n",
    "\n",
    "    # 분모가 0인 경우를 대비해 조건문 수정\n",
    "    train.loc[train[pairs[i][1]] == 0, pairs[i][0]+'D'+pairs[i][1]] = train.loc[train[pairs[i][1]] == 0, pairs[i][0]] / epsilon\n",
    "    test.loc[test[pairs[i][1]] == 0, pairs[i][0]+'D'+pairs[i][1]] = test.loc[test[pairs[i][1]] == 0, pairs[i][0]] / epsilon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train' 데이터프레임의 칼럼 이름을 문자열로 변환\n",
    "train.columns = train.columns.map(str)\n",
    "test.columns = test.columns.map(str)\n",
    "\n",
    "x = train.drop(['ID','grade'], axis=1 )\n",
    "y = train['grade']\n",
    "test  = test.drop('ID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampling\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "x,y = ADASYN(random_state = 42 ).fit_resample(x,y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터를 훈련 세트와 테스트 세트로 분리\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-31 18:11:36,383] A new study created in memory with name: Xgb\n",
      "[I 2024-01-31 18:13:40,526] Trial 0 finished with value: 0.9070487314183808 and parameters: {'n_estimators': 481, 'learning_rate': 0.14263178880828245, 'lambda': 0.07346740023932911, 'alpha': 0.5990598257128396, 'colsample_bytree': 0.4936111842654619, 'subsample': 0.49359671220172163, 'max_depth': 2, 'min_child_weight': 44}. Best is trial 0 with value: 0.9070487314183808.\n",
      "[I 2024-01-31 18:20:35,403] Trial 1 finished with value: 0.9254736490135481 and parameters: {'n_estimators': 669, 'learning_rate': 0.1063568503805088, 'lambda': 0.0030378649352844423, 'alpha': 0.9699399423098324, 'colsample_bytree': 0.899465584480253, 'subsample': 0.5274034664069657, 'max_depth': 3, 'min_child_weight': 10}. Best is trial 1 with value: 0.9254736490135481.\n",
      "[I 2024-01-31 18:25:52,949] Trial 2 finished with value: 0.9173360965484878 and parameters: {'n_estimators': 422, 'learning_rate': 0.07895108652901955, 'lambda': 0.04376255684556946, 'alpha': 0.2919379110578439, 'colsample_bytree': 0.7671117368334277, 'subsample': 0.4836963163912251, 'max_depth': 4, 'min_child_weight': 19}. Best is trial 1 with value: 0.9254736490135481.\n",
      "[I 2024-01-31 18:33:56,364] Trial 3 finished with value: 0.9241143563295676 and parameters: {'n_estimators': 548, 'learning_rate': 0.11788380622825553, 'lambda': 0.020767704433677616, 'alpha': 0.514720203975198, 'colsample_bytree': 0.7554487413172255, 'subsample': 0.42787024763199866, 'max_depth': 7, 'min_child_weight': 9}. Best is trial 1 with value: 0.9254736490135481.\n",
      "[I 2024-01-31 18:35:55,937] Trial 4 finished with value: 0.9157253098960274 and parameters: {'n_estimators': 224, 'learning_rate': 0.14235838781937332, 'lambda': 0.09659757127438139, 'alpha': 0.8085889507683447, 'colsample_bytree': 0.5827682615040224, 'subsample': 0.45860326840383037, 'max_depth': 8, 'min_child_weight': 23}. Best is trial 1 with value: 0.9254736490135481.\n",
      "[I 2024-01-31 18:37:58,987] Trial 5 finished with value: 0.9202639163017503 and parameters: {'n_estimators': 271, 'learning_rate': 0.07452894806163489, 'lambda': 0.004404463590406622, 'alpha': 0.9094110816767033, 'colsample_bytree': 0.5552679889600102, 'subsample': 0.7975133706123891, 'max_depth': 4, 'min_child_weight': 27}. Best is trial 1 with value: 0.9254736490135481.\n",
      "[W 2024-01-31 18:38:48,829] Trial 6 failed with parameters: {'n_estimators': 624, 'learning_rate': 0.028135741101066293, 'lambda': 0.0969888781486913, 'alpha': 0.7753576905377534, 'colsample_bytree': 0.9636993649385135, 'subsample': 0.9368964102565893, 'max_depth': 7, 'min_child_weight': 47} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kiwoongyoon/.local/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_13169/2451360025.py\", line 29, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial,X_train,  y_train ,X_valid , y_valid ),n_trials=14, timeout = 8300 )\n",
      "  File \"/tmp/ipykernel_13169/2451360025.py\", line 22, in objective\n",
      "    model.fit(train_x, train_y)\n",
      "  File \"/home/kiwoongyoon/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/kiwoongyoon/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1490, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/kiwoongyoon/.local/lib/python3.10/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/kiwoongyoon/.local/lib/python3.10/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/kiwoongyoon/.local/lib/python3.10/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n",
      "[W 2024-01-31 18:38:48,831] Trial 6 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/kiwoongyoon/바탕화면/DACON/대출등급 예측/code/sota3.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# study_xgb.optimize(objective, n_trials=5)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m study \u001b[39m=\u001b[39m  optuna\u001b[39m.\u001b[39mcreate_study(study_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mXgb\u001b[39m\u001b[39m'\u001b[39m, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m,sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m) )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(\u001b[39mlambda\u001b[39;49;00m trial: objective(trial,X_train,  y_train ,X_valid , y_valid ),n_trials\u001b[39m=\u001b[39;49m\u001b[39m14\u001b[39;49m, timeout \u001b[39m=\u001b[39;49m \u001b[39m8300\u001b[39;49m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest score:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/study.py:442\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     _optimize(\n\u001b[1;32m    443\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    444\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    445\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    446\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    447\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    448\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[1;32m    449\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    450\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    451\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    452\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/home/kiwoongyoon/바탕화면/DACON/대출등급 예측/code/sota3.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# study_xgb.optimize(objective, n_trials=5)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m study \u001b[39m=\u001b[39m  optuna\u001b[39m.\u001b[39mcreate_study(study_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mXgb\u001b[39m\u001b[39m'\u001b[39m, direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m'\u001b[39m,sampler\u001b[39m=\u001b[39mTPESampler(seed\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m) )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m study\u001b[39m.\u001b[39moptimize(\u001b[39mlambda\u001b[39;00m trial: objective(trial,X_train,  y_train ,X_valid , y_valid ),n_trials\u001b[39m=\u001b[39m\u001b[39m14\u001b[39m, timeout \u001b[39m=\u001b[39m \u001b[39m8300\u001b[39m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest trial:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_trial\u001b[39m.\u001b[39mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mBest score:\u001b[39m\u001b[39m'\u001b[39m, study\u001b[39m.\u001b[39mbest_value)\n",
      "\u001b[1;32m/home/kiwoongyoon/바탕화면/DACON/대출등급 예측/code/sota3.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m param \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mmulti:softmax\u001b[39m\u001b[39m'\u001b[39m,  \u001b[39m# 목표를 다중 클래스 분류로 설정\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m170\u001b[39m, \u001b[39m1000\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmin_child_weight\u001b[39m\u001b[39m'\u001b[39m: trial\u001b[39m.\u001b[39msuggest_int(\u001b[39m'\u001b[39m\u001b[39mmin_child_weight\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m }\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m model \u001b[39m=\u001b[39mXGBClassifier(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparam)  \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_x, train_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(val_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kiwoongyoon/%EB%B0%94%ED%83%95%ED%99%94%EB%A9%B4/DACON/%EB%8C%80%EC%B6%9C%EB%93%B1%EA%B8%89%20%EC%98%88%EC%B8%A1/code/sota3.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m score \u001b[39m=\u001b[39m macro_f1_score(val_y, preds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1462\u001b[0m (\n\u001b[1;32m   1463\u001b[0m     model,\n\u001b[1;32m   1464\u001b[0m     metric,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[1;32m   1470\u001b[0m )\n\u001b[1;32m   1471\u001b[0m train_dmatrix, evals \u001b[39m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1472\u001b[0m     missing\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmissing,\n\u001b[1;32m   1473\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1487\u001b[0m     feature_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_types,\n\u001b[1;32m   1488\u001b[0m )\n\u001b[0;32m-> 1490\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster \u001b[39m=\u001b[39m train(\n\u001b[1;32m   1491\u001b[0m     params,\n\u001b[1;32m   1492\u001b[0m     train_dmatrix,\n\u001b[1;32m   1493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_num_boosting_rounds(),\n\u001b[1;32m   1494\u001b[0m     evals\u001b[39m=\u001b[39;49mevals,\n\u001b[1;32m   1495\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds,\n\u001b[1;32m   1496\u001b[0m     evals_result\u001b[39m=\u001b[39;49mevals_result,\n\u001b[1;32m   1497\u001b[0m     obj\u001b[39m=\u001b[39;49mobj,\n\u001b[1;32m   1498\u001b[0m     custom_metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1499\u001b[0m     verbose_eval\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   1500\u001b[0m     xgb_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1501\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1502\u001b[0m )\n\u001b[1;32m   1504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n\u001b[1;32m   1505\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    184\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m bst\u001b[39m.\u001b[39;49mupdate(dtrain, i, obj)\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m cb_container\u001b[39m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    187\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1915\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m fobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1918\u001b[0m     _check_call(_LIB\u001b[39m.\u001b[39;49mXGBoosterUpdateOneIter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1919\u001b[0m                                             ctypes\u001b[39m.\u001b[39;49mc_int(iteration),\n\u001b[1;32m   1920\u001b[0m                                             dtrain\u001b[39m.\u001b[39;49mhandle))\n\u001b[1;32m   1921\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1922\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict(dtrain, output_margin\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# XGBoost Optuna\n",
    "\n",
    "\n",
    "def macro_f1_score(y_true, y_pred):\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return f1  # Optuna는 최대화를 목표로 하므로 1 - f1이 아닌 f1을 반환\n",
    "\n",
    "\n",
    "def objective(trial, train_x, train_y, val_x, val_y):\n",
    "    param = {\n",
    "        'objective': 'multi:softmax',  # 목표를 다중 클래스 분류로 설정\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 170, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.0005, 0.15),\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 0.1),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 1),\n",
    "        'max_depth': trial.suggest_int('max_depth',2,10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n",
    "    }\n",
    "    model =XGBClassifier(**param)  \n",
    "    model.fit(train_x, train_y)\n",
    "    preds = model.predict(val_x)\n",
    "    score = macro_f1_score(val_y, preds)\n",
    "    return score\n",
    "          \n",
    "# study_xgb.optimize(objective, n_trials=5)\n",
    "study =  optuna.create_study(study_name='Xgb', direction='maximize',sampler=TPESampler(seed=42) )\n",
    "study.optimize(lambda trial: objective(trial,X_train,  y_train ,X_valid , y_valid ),n_trials=14, timeout = 8300 )\n",
    "print('Best trial:', study.best_trial.params)\n",
    "print('Best score:', study.best_value)\n",
    "\n",
    "# 기존 특성들 :[I 2024-01-22 14:42:19,100] Trial 8 finished with value: 0.9374472481030386 and parameters: {'n_estimators': 353, 'learning_rate': 0.08163306443215815, 'lambda': 0.014951498272501501, 'alpha': 0.8023947837732857, 'colsample_bytree': 0.44473038620786254, 'subsample': 0.9921321619603104, 'max_depth': 8, 'min_child_weight': 10}. Best is trial 8 with value: 0.9374472481030386.\n",
    "# 새 특성+ 분산0인것 제외 :  and parameters: {'n_estimators': 752, 'learning_rate': 0.08513602429461944, 'lambda': 0.03391515402646526, 'alpha': 0.6532768202909376, 'colsample_bytree': 0.4470774309800684, 'subsample': 0.7236838914160535, 'max_depth': 8, 'min_child_weight': 1}. Best is trial 13 with value: 0.937929329398787."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# [I 2024-01-29 14:58:47,402] A new study created in memory with name: Xgb\n",
    "# [I 2024-01-29 15:01:34,810] Trial 0 finished with value: 0.950629624448874 and parameters: {'n_estimators': 481, 'learning_rate': 0.14263178880828245, 'lambda': 0.07346740023932911, 'alpha': 0.5990598257128396, 'colsample_bytree': 0.4936111842654619, 'subsample': 0.49359671220172163, 'max_depth': 2, 'min_child_weight': 44}. Best is trial 0 with value: 0.950629624448874.\n",
    "# [I 2024-01-29 15:10:54,948] Trial 1 finished with value: 0.9628777155557814 and parameters: {'n_estimators': 669, 'learning_rate': 0.1063568503805088, 'lambda': 0.0030378649352844423, 'alpha': 0.9699399423098324, 'colsample_bytree': 0.899465584480253, 'subsample': 0.5274034664069657, 'max_depth': 3, 'min_child_weight': 10}. Best is trial 1 with value: 0.9628777155557814.\n",
    "# [W 2024-01-29 15:16:16,162] Trial 2 failed with parameters: {'n_estimators': 422, 'learning_rate': 0.07895108652901955, 'lambda': 0.04376255684556946, 'alpha': 0.2919379110578439, 'colsample_bytree': 0.7671117368334277, 'subsample': 0.4836963163912251, 'max_depth': 4, 'min_child_weight': 19} because of the following error: KeyboardInterrupt().\n",
    "# estimators': 669, 'learning_rate': 0.1063568503805088, 'lambda': 0.0030378649352844423, 'alpha': 0.9699399423098324, 'colsample_bytree': 0.899465584480253, 'subsample': 0.5274034664069657, 'max_depth': 3, 'min_child_weight': 10}. Best is trial 1 with value: 0.9254736490135481.\n",
    "\n",
    "# Traceback (most recent call last):\n",
    "\n",
    "# 파라미터 설정\n",
    "params = {'n_estimators': 669, \n",
    "          'learning_rate': 0.1063568503805088, \n",
    "          'lambda': 0.0030378649352844423, \n",
    "          'alpha': 0.9699399423098324, \n",
    "          'colsample_bytree': 0.899465584480253, \n",
    "          'subsample': 0.5274034664069657, \n",
    "          'max_depth': 3, \n",
    "          'min_child_weight': 10}\n",
    "\n",
    "# XGBClassifier에 파라미터 설정\n",
    "xgb = XGBClassifier(**params)\n",
    "\n",
    "# 모델 학습\n",
    "xgb.fit(x, y)\n",
    "\n",
    "# 예측\n",
    "pred = xgb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>대출등급</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64192</th>\n",
       "      <td>TEST_64192</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64193</th>\n",
       "      <td>TEST_64193</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64194</th>\n",
       "      <td>TEST_64194</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64195</th>\n",
       "      <td>TEST_64195</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64196</th>\n",
       "      <td>TEST_64196</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64197 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID 대출등급\n",
       "0      TEST_00000    B\n",
       "1      TEST_00001    B\n",
       "2      TEST_00002    A\n",
       "3      TEST_00003    C\n",
       "4      TEST_00004    C\n",
       "...           ...  ...\n",
       "64192  TEST_64192    D\n",
       "64193  TEST_64193    D\n",
       "64194  TEST_64194    D\n",
       "64195  TEST_64195    C\n",
       "64196  TEST_64196    A\n",
       "\n",
       "[64197 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample_submission['대출등급'] = pred \n",
    "\n",
    "# 딕셔너리 뒤집기\n",
    "inv_grade_dict = {v: k for k, v in grade_dict.items()}\n",
    "\n",
    "# 'grade' 열을 다시 알파벳으로 변경\n",
    "sample_submission['대출등급'] = sample_submission['대출등급'].map(inv_grade_dict)\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('../data/targetencoding1.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
